{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Assignment 3\n",
        "## Practical Deep Learning for Language Processing\n",
        "\n",
        "01/23/2023\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Part A"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "if torch.cuda.is_available(): \n",
        "    device = \"cuda\"\n",
        "else:\n",
        "    device = \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, pipeline, DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
        "sequence_clf_model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-cased\", \n",
        "                                                                         num_labels = 2, \n",
        "                                                                         id2label={0: \"negative\", 1: \"positive\"}, \n",
        "                                                                         label2id={\"negative\": 0, \"positive\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 3, 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset imdb (/home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/imdb/plain_text/1.0.0/2fdd8b9bcadd6e7055e742a706876ba43f19faee861df134affd7a3f60fc38a1)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f6dd98b740e04d629d6d57ccb13bd1dc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# load the data with the predefined train-test split\n",
        "imdb_train, imdb_test = load_dataset('imdb', split=['train', 'test'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# further perform a test-validation split\n",
        "\n",
        "# get the number of examples per class\n",
        "n_split = int(len(imdb_test) / 2)\n",
        "# set the sizes for subsetting\n",
        "subset_num = (4000, 1000, 1000)\n",
        "# get a randomized order\n",
        "shuffle = torch.randperm(n_split)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get the subsets\n",
        "imdb_train = imdb_train.select(torch.concat([shuffle, (shuffle + n_split)])).\\\n",
        "    select(torch.concat([torch.arange(0, subset_num[0]/2), torch.arange(0, subset_num[0]/2) + n_split]))\n",
        "imdb_val = imdb_test.select(torch.concat([shuffle, (shuffle + n_split)])).\\\n",
        "    select(torch.concat([torch.arange(subset_num[1]/2, subset_num[1]/2 + subset_num[2]/2), torch.arange(subset_num[1]/2, subset_num[1]/2 + subset_num[2]/2) + n_split]))\n",
        "imdb_test = imdb_test.select(torch.concat([shuffle, (shuffle + n_split)])).\\\n",
        "    select(torch.concat([torch.arange(0, subset_num[1]/2), torch.arange(0, subset_num[1]/2) + n_split]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# simple function to batch tokenize utterances with truncation\n",
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation = True, padding = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a804e6ef23c64bc188b5842543b583a5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b8d3ff845347444b96fcb093182a629a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a72aad16d2c24d2695a8930c1fe764e8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# apply the tokenization in batches to all data sets\n",
        "imdb_train = imdb_train.map(preprocess_function, batched=True).remove_columns(\"text\")\n",
        "imdb_val = imdb_val.map(preprocess_function, batched=True).remove_columns(\"text\")\n",
        "imdb_test = imdb_test.map(preprocess_function, batched=True).remove_columns(\"text\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6, 7, 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "    # setting the epochs for task 7\n",
        "    num_train_epochs = 3,\n",
        "    # setting the checkpoint directory and interval for task 8\n",
        "    output_dir = \"./MyIMDBModel\",\n",
        "    save_strategy = \"steps\",\n",
        "    save_steps = 50,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps = 50,\n",
        "    logging_steps = 50,\n",
        "    log_level='info',\n",
        "    # proposed settings from task 6\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64, \n",
        "    warmup_steps=100, \n",
        "    weight_decay=0.01, \n",
        "    logging_strategy='steps', \n",
        "    logging_dir='./logs', \n",
        "    fp16 = (device == \"cuda\"), \n",
        "    load_best_model_at_end=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "# load the metric\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "# a function to compute the metrics from predicted logits and ground truth\n",
        "def compute_metrics(eval_pred):\n",
        "    # separate the items\n",
        "    logits, labels = eval_pred\n",
        "    # logits are given in two columns: get the prediction as the column with the higher logit\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    # compute the f1 metric\n",
        "    return f1_metric.compute(predictions = predictions, references = labels, average = \"macro\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "# compile the trainer class\n",
        "trainer = Trainer(\n",
        "    model = sequence_clf_model,\n",
        "    args = training_args,\n",
        "    train_dataset = imdb_train,\n",
        "    eval_dataset = imdb_test,\n",
        "    compute_metrics = compute_metrics\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 11, 12\n",
        "Because Tensor Board requires opening a port and I compute this assignment on the cluster where this is not easily accomplished, I do not use it for evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [16/16 00:13]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6942612528800964,\n",
              " 'eval_f1': 0.46486765996849333,\n",
              " 'eval_runtime': 2.5766,\n",
              " 'eval_samples_per_second': 388.11,\n",
              " 'eval_steps_per_second': 6.21}"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# get evaluation prior to training\n",
        "# this will use the loaded weights\n",
        "trainer.evaluate()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/pfs/work7/workspace/scratch/tu_zxobe27-ds_project/conda/envs/nlp_cuda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 4000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 375\n",
            "  Number of trainable parameters = 65783042\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='375' max='375' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [375/375 01:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.683400</td>\n",
              "      <td>0.641838</td>\n",
              "      <td>0.529858</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.467300</td>\n",
              "      <td>0.463496</td>\n",
              "      <td>0.782286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.306200</td>\n",
              "      <td>0.397723</td>\n",
              "      <td>0.838112</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.282600</td>\n",
              "      <td>0.327772</td>\n",
              "      <td>0.864997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.254700</td>\n",
              "      <td>0.334565</td>\n",
              "      <td>0.862997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.124700</td>\n",
              "      <td>0.429809</td>\n",
              "      <td>0.871975</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.089700</td>\n",
              "      <td>0.413689</td>\n",
              "      <td>0.886991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-50\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-50/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-50/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-100\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-100/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-100/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-150\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-150/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-150/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-200\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-200/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-250\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-250/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-250/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-300\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-300/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-300/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 1000\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MyIMDBModel/checkpoint-350\n",
            "Configuration saved in ./MyIMDBModel/checkpoint-350/config.json\n",
            "Model weights saved in ./MyIMDBModel/checkpoint-350/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./MyIMDBModel/checkpoint-200 (score: 0.32777202129364014).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=375, training_loss=0.3012816460927327, metrics={'train_runtime': 95.4594, 'train_samples_per_second': 125.708, 'train_steps_per_second': 3.928, 'total_flos': 1589608783872000.0, 'train_loss': 0.3012816460927327, 'epoch': 3.0})"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Overall loss decreased from 0.694 pre-training to a low of 0.328 after step 200. The F1 score improved from 0.465 to 0.865.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 13"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", sequence_clf_model, tokenizer=tokenizer, device=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9862398505210876}]"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"Fargo is amazingly entertaining.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The first text is correctly predicted to be positive."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9294151067733765}]"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"Overall I think that Star Wars 8 is the worst thing that happened in 2017.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The second text is correctly predicted to be negative."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9377620816230774}]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe('The Room is probably the worst movie that I ever loved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally the third text is a very complicated example which the model predicts to be negative. I would however argue that the overall sentiment of the sentence is positive because the focal word is \"loved\". I would have at least expected the score of the prediction to be much lower. Perhaps BERT has had some bad experiences with love? ;)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 14"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['model.pkl']"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "# export the tokenizer and model\n",
        "joblib.dump(tokenizer, \"tokenizer.pkl\")\n",
        "joblib.dump(sequence_clf_model, \"model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part B\n",
        "## 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset glue (/home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "85524f40cc1f405095d9445dd15daad1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "# loading the data\n",
        "stsb_train, stsb_val = load_dataset('glue', 'stsb', split=[\"train\", \"validation\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "# defining the length of the validation set\n",
        "n_split = len(stsb_val)\n",
        "# taking a subset of 5000 observations in the training sample\n",
        "stsb_train = stsb_train.select(torch.arange(5000))\n",
        "# splitting the validation sample in half and assigning the first half as the testing set\n",
        "stsb_test = stsb_val.select(torch.randperm(n_split)[:int(n_split / 2)])\n",
        "stsb_val = stsb_val.select(torch.randperm(n_split)[int(n_split / 2):])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, pipeline, DistilBertForSequenceClassification, DistilBertTokenizerFast, DataCollatorWithPadding\n",
        "# loading the model with the number of labels set as 1 to achieve regression\n",
        "regression_clf_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', num_labels = 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/vocab.txt\n",
            "loading file tokenizer.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "Loading cached processed dataset at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-69c5f35a9ce38d1f.arrow\n",
            "Loading cached processed dataset at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-168be6573cba4cee.arrow\n",
            "Loading cached processed dataset at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/glue/stsb/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-fe4ce424f3e8ce7d.arrow\n"
          ]
        }
      ],
      "source": [
        "# loading the tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "# loading the collator which we use for efficient padding\n",
        "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)\n",
        "\n",
        "# simple function to batch tokenize utterances with truncation\n",
        "## merging with [SEP] is done automatically by the tokenizer as per the documentation (https://huggingface.co/docs/transformers/v4.26.0/en/main_classes/tokenizer#transformers.PreTrainedTokenizerFast)\n",
        "def preprocess_function(example):\n",
        "    return tokenizer(example[\"sentence1\"], example[\"sentence2\"], truncation = True)\n",
        "\n",
        "# apply the tokenization in batches and remove columns that are not needed after\n",
        "stsb_train = stsb_train.map(preprocess_function, batched=True).remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "stsb_val = stsb_val.map(preprocess_function, batched=True).remove_columns([\"sentence1\", \"sentence2\", \"idx\"])\n",
        "stsb_test = stsb_test.map(preprocess_function, batched=True).remove_columns([\"sentence1\", \"sentence2\", \"idx\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
          ]
        }
      ],
      "source": [
        "# setting the training arguments\n",
        "training_args = TrainingArguments(\n",
        "    # setting epochs and new output directory\n",
        "    num_train_epochs = 4,\n",
        "    output_dir = \"./MySTSBModel\",\n",
        "    # everything below is identical\n",
        "    save_strategy = \"steps\",\n",
        "    save_steps = 50,\n",
        "    evaluation_strategy='steps',\n",
        "    eval_steps = 50,\n",
        "    logging_steps = 50,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=64, \n",
        "    warmup_steps=100, \n",
        "    weight_decay=0.01, \n",
        "    logging_strategy='steps', \n",
        "    logging_dir='./logs', \n",
        "    fp16 = (device == \"cuda\"), \n",
        "    load_best_model_at_end=True,\n",
        "    log_level='info'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "import evaluate\n",
        "import numpy as np\n",
        "# load the metrics\n",
        "corr_pearson = evaluate.load(\"pearsonr\")\n",
        "corr_spearman = evaluate.load(\"spearmanr\")\n",
        "\n",
        "# a function to compute the metrics from predicted logits and ground truth\n",
        "def compute_metrics(eval_pred):\n",
        "    # separate the items\n",
        "    reg_preds, labels = eval_pred\n",
        "    # compute the two correlation coefficients\n",
        "    return {\"pearson\": corr_pearson.compute(predictions = np.squeeze(reg_preds), references = labels)[\"pearsonr\"], \n",
        "            \"spearman\": corr_spearman.compute(predictions = np.squeeze(reg_preds), references = labels)[\"spearmanr\"]}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using cuda_amp half precision backend\n"
          ]
        }
      ],
      "source": [
        "# define the trainer:\n",
        "trainer = Trainer(\n",
        "    model=regression_clf_model,\n",
        "    args=training_args,\n",
        "    train_dataset = stsb_train,\n",
        "    eval_dataset = stsb_val,\n",
        "    compute_metrics=compute_metrics,\n",
        "    data_collator=data_collator\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/pfs/work7/workspace/scratch/tu_zxobe27-ds_project/conda/envs/nlp_cuda/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n",
            "***** Running training *****\n",
            "  Num examples = 5000\n",
            "  Num Epochs = 4\n",
            "  Instantaneous batch size per device = 32\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 628\n",
            "  Number of trainable parameters = 65782273\n",
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='628' max='628' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [628/628 00:46, Epoch 4/4]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Pearson</th>\n",
              "      <th>Spearman</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>5.685100</td>\n",
              "      <td>2.269089</td>\n",
              "      <td>0.162055</td>\n",
              "      <td>0.131543</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>1.397500</td>\n",
              "      <td>0.992972</td>\n",
              "      <td>0.776604</td>\n",
              "      <td>0.775306</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.961900</td>\n",
              "      <td>0.978886</td>\n",
              "      <td>0.783636</td>\n",
              "      <td>0.774144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.777400</td>\n",
              "      <td>0.688031</td>\n",
              "      <td>0.831395</td>\n",
              "      <td>0.825778</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.662600</td>\n",
              "      <td>1.058583</td>\n",
              "      <td>0.819995</td>\n",
              "      <td>0.828979</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.644100</td>\n",
              "      <td>0.699469</td>\n",
              "      <td>0.843661</td>\n",
              "      <td>0.839887</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.521400</td>\n",
              "      <td>0.591362</td>\n",
              "      <td>0.854371</td>\n",
              "      <td>0.850726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.348500</td>\n",
              "      <td>0.685750</td>\n",
              "      <td>0.846772</td>\n",
              "      <td>0.845007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.393400</td>\n",
              "      <td>0.611058</td>\n",
              "      <td>0.852351</td>\n",
              "      <td>0.849114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.274800</td>\n",
              "      <td>0.635973</td>\n",
              "      <td>0.855210</td>\n",
              "      <td>0.851626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.261500</td>\n",
              "      <td>0.586860</td>\n",
              "      <td>0.856921</td>\n",
              "      <td>0.852370</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.244100</td>\n",
              "      <td>0.624741</td>\n",
              "      <td>0.858421</td>\n",
              "      <td>0.853796</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-50\n",
            "Configuration saved in ./MySTSBModel/checkpoint-50/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-50/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-100\n",
            "Configuration saved in ./MySTSBModel/checkpoint-100/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-100/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-150\n",
            "Configuration saved in ./MySTSBModel/checkpoint-150/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-150/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-200\n",
            "Configuration saved in ./MySTSBModel/checkpoint-200/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-200/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-250\n",
            "Configuration saved in ./MySTSBModel/checkpoint-250/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-250/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-300\n",
            "Configuration saved in ./MySTSBModel/checkpoint-300/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-300/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-350\n",
            "Configuration saved in ./MySTSBModel/checkpoint-350/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-350/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-400\n",
            "Configuration saved in ./MySTSBModel/checkpoint-400/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-400/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-450\n",
            "Configuration saved in ./MySTSBModel/checkpoint-450/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-450/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-500\n",
            "Configuration saved in ./MySTSBModel/checkpoint-500/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-500/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-550\n",
            "Configuration saved in ./MySTSBModel/checkpoint-550/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-550/pytorch_model.bin\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n",
            "Saving model checkpoint to ./MySTSBModel/checkpoint-600\n",
            "Configuration saved in ./MySTSBModel/checkpoint-600/config.json\n",
            "Model weights saved in ./MySTSBModel/checkpoint-600/pytorch_model.bin\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "Loading best model from ./MySTSBModel/checkpoint-550 (score: 0.5868598818778992).\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=628, training_loss=0.9787004130661108, metrics={'train_runtime': 46.0847, 'train_samples_per_second': 433.983, 'train_steps_per_second': 13.627, 'total_flos': 391966112142384.0, 'train_loss': 0.9787004130661108, 'epoch': 4.0})"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# perform the training\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 5000\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.15423133969306946,\n",
              " 'eval_pearson': 0.9619616158330276,\n",
              " 'eval_spearman': 0.9533286223393135,\n",
              " 'eval_runtime': 1.1424,\n",
              " 'eval_samples_per_second': 4376.561,\n",
              " 'eval_steps_per_second': 69.15,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate on train data\n",
        "trainer.evaluate(stsb_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.6391530632972717,\n",
              " 'eval_pearson': 0.8461880126641562,\n",
              " 'eval_spearman': 0.840871929112593,\n",
              " 'eval_runtime': 0.2236,\n",
              " 'eval_samples_per_second': 3353.476,\n",
              " 'eval_steps_per_second': 53.656,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 29,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate on test data\n",
        "trainer.evaluate(stsb_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 750\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'eval_loss': 0.5868598818778992,\n",
              " 'eval_pearson': 0.8569211303648085,\n",
              " 'eval_spearman': 0.8523696778320894,\n",
              " 'eval_runtime': 0.2302,\n",
              " 'eval_samples_per_second': 3258.393,\n",
              " 'eval_steps_per_second': 52.134,\n",
              " 'epoch': 4.0}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# evaluate on validation data\n",
        "trainer.evaluate(stsb_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I find that loss and correlation are expectedly significantly better in the training set. However correlation coefficients are still good at above 0.84 and similar between the test and validation sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "379a91ffc63749438eb2dc165af4a7fc",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[3.719]], dtype=float16), label_ids=None, metrics={'test_runtime': 0.0083, 'test_samples_per_second': 120.081, 'test_steps_per_second': 120.081})"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "# compile a dataset from the two sentences\n",
        "dataset = Dataset.from_list([{\"sentence1\": \"Tom Brady is a football player.\", \"sentence2\": \"Tom Brady is an American Football player.\"}])\n",
        "# get a prediction for that dataset\n",
        "trainer.predict(dataset.map(preprocess_function).remove_columns([\"sentence1\", \"sentence2\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "These two sentences are expectedly predicted to be very similar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdb04f9ca3b245a48b716e0db7ecff5c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/1 [00:00<?, ?ex/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 1\n",
            "  Batch size = 64\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "PredictionOutput(predictions=array([[1.018]], dtype=float16), label_ids=None, metrics={'test_runtime': 0.0083, 'test_samples_per_second': 120.419, 'test_steps_per_second': 120.419})"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from datasets import Dataset\n",
        "\n",
        "dataset = Dataset.from_list([{\"sentence1\": \"A technology destroying humandkind.\", \"sentence2\": \"The BERT transformer-based neural network.\"}])\n",
        "trainer.predict(dataset.map(preprocess_function).remove_columns([\"sentence1\", \"sentence2\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It appears that there is indeed little risk that BERT will destroy humandkind."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['stsb_model.pkl']"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "# export the tokenizer and model\n",
        "joblib.dump(tokenizer, \"stsb_tokenizer.pkl\")\n",
        "joblib.dump(regression_clf_model, \"stsb_model.pkl\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "# Part C\n",
        "## 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading configuration file config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"negative\",\n",
            "    \"1\": \"positive\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"label2id\": {\n",
            "    \"negative\": 0,\n",
            "    \"positive\": 1\n",
            "  },\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n",
            "loading weights file pytorch_model.bin from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/pytorch_model.bin\n",
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.bias', 'classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "from transformers import Trainer, TrainingArguments, pipeline, DistilBertForSequenceClassification, DistilBertTokenizerFast, DataCollatorWithPadding\n",
        "# loading the model\n",
        "classification_clf_model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-cased', \n",
        "                                                                               num_labels = 2, \n",
        "                                                                               id2label={0: \"negative\", 1: \"positive\"}, \n",
        "                                                                               label2id={\"negative\": 0, \"positive\": 1})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Found cached dataset glue (/home/tu/tu_tu/tu_zxobe27/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d5a544f8608c4849b0aef7ac99c6f988",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "# load datasets and metric\n",
        "sst2 = load_dataset(\"glue\", \"sst2\")\n",
        "# the proposed way of loading metrics seems to be outdated; I use a more recent one\n",
        "sst2_metric = evaluate.load(\"glue\", \"sst2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [],
      "source": [
        "# splitting the dataset as proposed\n",
        "texts = sst2['train']['sentence'] \n",
        "labels = sst2['train']['label'] \n",
        "val_texts = sst2['validation']['sentence'] \n",
        "val_labels = sst2['validation']['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "\n",
        "# define a custom dataset class\n",
        "class MyCustomDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, input_ids, attention_masks, labels):\n",
        "        self.input_ids = input_ids\n",
        "        self.attention_masks = attention_masks\n",
        "        self.values = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.values)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        ## I choose to not return tensors on GPU here as I have the tokenizer do this in the previous step\n",
        "        return self.input_ids[idx], self.attention_masks[idx], self.values[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "# set default so that every tensor is initialized on the GPU if available\n",
        "if torch.cuda.is_available(): \n",
        "    torch.set_default_tensor_type(torch.cuda.HalfTensor)\n",
        "    random_gen = torch.Generator(device = \"cuda\").manual_seed(42)\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    torch.set_default_tensor_type(torch.HalfTensor)\n",
        "    random_gen = torch.Generator(device = \"cpu\").manual_seed(42)\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "loading file vocab.txt from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/vocab.txt\n",
            "loading file tokenizer.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer.json\n",
            "loading file added_tokens.json from cache at None\n",
            "loading file special_tokens_map.json from cache at None\n",
            "loading file tokenizer_config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/tokenizer_config.json\n",
            "loading configuration file config.json from cache at /home/tu/tu_tu/tu_zxobe27/.cache/huggingface/hub/models--distilbert-base-cased/snapshots/9d7568e4b20ed5db15ee30e99c7219bde9990762/config.json\n",
            "Model config DistilBertConfig {\n",
            "  \"_name_or_path\": \"distilbert-base-cased\",\n",
            "  \"activation\": \"gelu\",\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.26.0\",\n",
            "  \"vocab_size\": 28996\n",
            "}\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# load and instantiate the tokenizer\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-cased')\n",
        "\n",
        "# tokenize, pad, truncate and move results to GPU tensors if available\n",
        "texts = tokenizer(texts, padding = True, truncation = True, return_tensors = \"pt\")\n",
        "val_texts = tokenizer(val_texts, padding = True, truncation = True, return_tensors = \"pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "# create datasets from the tokenzied tensors\n",
        "train_dataset = MyCustomDataset(texts[\"input_ids\"], texts[\"attention_mask\"], labels)\n",
        "val_dataset = MyCustomDataset(val_texts[\"input_ids\"], val_texts[\"attention_mask\"], val_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# create data loaders from the datasets\n",
        "train_dataloader = DataLoader(train_dataset, batch_size = 16, shuffle = True, generator = random_gen)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size = 16, shuffle = True, generator = random_gen)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# define the AdamW optimizer from PyTorch\n",
        "optimizer = torch.optim.AdamW(classification_clf_model.parameters(), lr = 5e-5)\n",
        "\n",
        "# define the Cross-Entropy loss function\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Softmax Metric for evaluation\n",
        "softmax = torch.nn.Softmax(dim = -1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8, 9, 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "starting epoch: 1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4210/4210 [03:03<00:00, 22.88batch/s,  loss: 0.2325539238689955] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1 | metric: {'accuracy': 0.8979357798165137}\n",
            "starting epoch: 2\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4210/4210 [03:04<00:00, 22.88batch/s,  loss: 0.12242913089980859]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 2 | metric: {'accuracy': 0.8887614678899083}\n",
            "starting epoch: 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4210/4210 [03:04<00:00, 22.86batch/s,  loss: 0.08599835398649919]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 3 | metric: {'accuracy': 0.893348623853211}\n",
            "starting epoch: 4\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 4210/4210 [03:04<00:00, 22.88batch/s,  loss: 0.06463774304200169] \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 4 | metric: {'accuracy': 0.8864678899082569}\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "# set the number of epochs\n",
        "n_epochs = 4\n",
        "\n",
        "# send the model to the selected device\n",
        "classification_clf_model.to(device)\n",
        "\n",
        "# iterate over epochs\n",
        "for epoch in range(n_epochs):\n",
        "    \n",
        "    print(f\"starting epoch: {epoch + 1}\")\n",
        "    \n",
        "    ## set training mode\n",
        "    classification_clf_model.train()\n",
        "    \n",
        "    # start counting loss and batches before each epoch\n",
        "    sum_loss = 0\n",
        "    n_batches = 0\n",
        "    \n",
        "    # establish a progress bar over the dataloader items        \n",
        "    with tqdm(train_dataloader, unit = \"batch\", miniters = 10) as tepoch:\n",
        "        \n",
        "        # iterate over the items of the dataloader\n",
        "        for batch in tepoch:\n",
        "            \n",
        "            # reset the gradients\n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            # forward pass the items of the batch\n",
        "            outputs = classification_clf_model(batch[0], batch[1])\n",
        "            \n",
        "            # the criterion defined above does not require any Softmax beforehands because it does this step by itself\n",
        "            loss = criterion(outputs.logits, batch[2])\n",
        "            \n",
        "            # compute the gradients\n",
        "            loss.backward()\n",
        "            \n",
        "            # update the weights\n",
        "            optimizer.step()\n",
        "            \n",
        "            # add to counters\n",
        "            n_batches += 1\n",
        "            sum_loss += loss.item()\n",
        "            \n",
        "            # update tqdm with loss information every 100 batches\n",
        "            if (n_batches % 100) == 0:\n",
        "                tepoch.set_postfix_str(f\" loss: {(sum_loss / n_batches)}\", refresh = True)\n",
        "        \n",
        "    ## set evaluation mode\n",
        "    classification_clf_model.eval()\n",
        "    \n",
        "    # iterate over items in the dataloader\n",
        "    for idx, batch in enumerate(val_dataloader):\n",
        "                \n",
        "        # evaluate without computing gradients\n",
        "        with torch.no_grad():\n",
        "            # forward pass\n",
        "            outputs = classification_clf_model(batch[0], batch[1])\n",
        "\n",
        "        # extract logits\n",
        "        logits = outputs.logits\n",
        "        # do softmax\n",
        "        scaled_logits = softmax(logits)\n",
        "        # get the columns of the highest scaled logit as prediction\n",
        "        predictions = torch.argmax(logits, dim = -1)\n",
        "        # add the predicted batch to the metric\n",
        "        sst2_metric.add_batch(predictions = predictions, references = batch[2])\n",
        "\n",
        "    # compute and print the metric\n",
        "    print(f\"epoch: {epoch + 1} | metric: {sst2_metric.compute()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I finally classify the same sentences as in Part A and get similar results. This is of course very encouraging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "pipe = pipeline(\"text-classification\", classification_clf_model, tokenizer = tokenizer, device = 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'positive', 'score': 0.9998492002487183}]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"Fargo is amazingly entertaining.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9997366070747375}]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe(\"Overall I think that Star Wars 8 is the worst thing that happened in 2017.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'label': 'negative', 'score': 0.9997199177742004}]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pipe('The Room is probably the worst movie that I ever loved.')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['sst2_model.pkl']"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "# export the tokenizer and model\n",
        "joblib.dump(tokenizer, \"sst2_tokenizer.pkl\")\n",
        "joblib.dump(classification_clf_model, \"sst2_model.pkl\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
